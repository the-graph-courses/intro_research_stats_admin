---
title: 'Estimation 2: Standard Error and Confidence intervals'
format:
  html:
    embed-resources: true
---

```{r, echo = F, message = F, warning = F}
# Load packages
if (!require(pacman)) install.packages("pacman")
pacman::p_load(rlang, tidyverse, knitr, here, reactable)

# Source functions
source(here("global/functions/lesson_functions.R"))

# Knitr options
knitr::opts_chunk$set(
  warning = F, message = F,
  class.source = "tgc-code-block", error = T
)

# Set ggplot theme
theme_set(theme_minimal())
```


# Introduction

How sure can we be that an election poll, a drug trial, or a customer-satisfaction survey reflects the real world?  
**This lesson unlocks the statistician’s answer: *confidence intervals* (CIs).**  
To get there, we first need to master the **standard error (SE)** and the logic of the **sampling distribution**.

---

# Dataset: Diabetes in China

We will use the same Chinese diabetes study introduced earlier:

```{r}
library(tidyverse)
diabetes_china_chen <- read_csv(here::here("data/diabetes_china_chen.csv"))
```

---

# 1 Standard Error

## 1.1 Why SE Matters

*The sampling distribution tightens as sample size grows.*
That tightening—the reduction in variability from one random sample to the next—is quantified by the **standard error**.

> **Standard error = “typical distance between a sample statistic and the true population value.”**

### Key idea

| Data context              | Spread measure              | Interpretation                |
| ------------------------- | --------------------------- | ----------------------------- |
| **Raw observations**      | **Standard Deviation (SD)** | Variation among *individuals* |
| **Sampling distribution** | **Standard Error (SE)**     | Variation among *statistics*  |

When we talk about *precision* we talk about SE, not SD.

---

## 1.2 SE Formulae

If the population SD, $\sigma$, is known:

$$
\boxed{\displaystyle
\text{SE}(\bar X)=\frac{\sigma}{\sqrt{n}}
}
$$

In practice $\sigma$ is unknown, so we plug in the sample SD, $s$:

$$
\boxed{\displaystyle
\widehat{\text{SE}}(\bar x)=\frac{s}{\sqrt{n}}
}
$$

**Doubling the sample size does *not* halve the SE—because of the square-root law.**

---

## 1.3 Worked Simulation

The block below repeatedly samples 100 people, records their systolic blood-pressure (SBP) mean, and compares the empirical SE with the theoretical formula.

```{r}
set.seed(2025)
n          <- 100
n_sim      <- 5000
pop_sd     <- sd(diabetes_china_chen$sbp_mm_hg, na.rm = TRUE)

sam_means  <- replicate(n_sim, {
  sample(diabetes_china_chen$sbp_mm_hg, n, replace = TRUE) |> mean(na.rm = TRUE)
})

emp_se     <- sd(sam_means)
theo_se    <- pop_sd / sqrt(n)

emp_se
theo_se
```

```{r}
# Visualise the sampling distribution of x̄

ggplot(data.frame(xbar = sam_means), aes(x = xbar)) +
  geom_histogram(bins = 30, colour = "white") +
  geom_vline(aes(xintercept = mean(xbar)), linetype = "dashed") +
  labs(title = "Sampling distribution of the mean (n = 100)",
       x = "Sample mean SBP (mmHg)",
       y = "Frequency")
```

---

# 2 Confidence Intervals

## 2.1 From Point Estimate to Interval Estimate

Every point estimate is *uncertain* by roughly $\pm$ 1 SE.  A **confidence interval** formalises that uncertainty by stretching the estimate outward by a *critical value*.

### 95 % CI for a Mean (population SD known)

$$
\boxed{\displaystyle
\bar x \;\pm\; z_{\;0.975}\times \frac{\sigma}{\sqrt{n}}
}
\qquad(\text{with } z_{0.975}=1.96)
$$

### 95 % CI for a Mean (σ unknown → *t* distribution)

$$
\boxed{\displaystyle
\bar x \;\pm\; t_{\,0.975,\;df=n-1}\times \frac{s}{\sqrt{n}}
}
$$

> **Interpretation (classical).**  In *repeated* sampling, **95 %** of the intervals constructed this way will contain the true mean μ.

::: callout-important
**Misconception alert:** *“There is a 95 % chance μ lies in this one interval.”*
No. μ is fixed; the interval is random. Either this interval contains μ or it does not—we just do not know which. The 95 % refers to the long-run success rate of the method.
:::

---

## 2.2 Factors That Control CI Width

| Factor                               | Mechanism                      | Result         |
| ------------------------------------ | ------------------------------ | -------------- |
| **Sample size $n$** ↑                | SE ↓ (∝ 1/√n)                  | CI **narrows** |
| **Confidence level** ↑ (95 % → 99 %) | Critical value ↑ (1.96 → 2.58) | CI **widens**  |
| **Data SD $σ$** ↑                    | SE ↑                           | CI **widens**  |

---

## 2.3 Illustrative Example

> **Scenario** A random sample of $n=100$ university students reports an average study time of
> $\bar x = 3.2$ h per day with sample SD $s = 2.5$ h.
> Construct a 95 % confidence interval for the population mean study time.

```{r}
xbar <- 3.2
s    <- 2.5
n    <- 100
se   <- s / sqrt(n)
crit <- qt(0.975, df = n - 1)

lower <- xbar - crit * se
upper <- xbar + crit * se
c(lower, upper)
```

$$
3.2\pm1.96\times0.25=3.2\pm0.49\quad\Rightarrow\quad[2.71,\,3.69]\text{ hours}
$$

**Interpretation** We are 95 % confident that the *average* study time for *all* students lies between **2.7 h and 3.7 h per day**.

---

## 2.4 CIs and Hypothesis Tests

For a two-sided test at α = 0.05:

* **If the 95 % CI excludes the null value** (e.g., 0 for a difference), **p < 0.05** → reject $H_0$.
* **If the 95 % CI includes the null value, p > 0.05** → fail to reject $H_0$.

Thus CIs provide **both** an estimate **and** a significance decision in one graphic.

---

## 2.5 More CI Templates

| Parameter                             | Point estimate      | 95 % CI (large-sample)                                                                 |
| ------------------------------------- | ------------------- | -------------------------------------------------------------------------------------- |
| Population proportion $p$             | $\hat p$            | $\hat p \pm 1.96\sqrt{\dfrac{\hat p(1-\hat p)}{n}}$                                    |
| Difference in two means $\mu_1-\mu_2$ | $\bar x_1-\bar x_2$ | $(\bar x_1-\bar x_2)\pm t_{.975,df}\times\sqrt{\dfrac{s_1^2}{n_1}+\dfrac{s_2^2}{n_2}}$ |
| Slope $β_1$ in simple regression      | $b_1$               | $b_1 \pm t_{.975,df}\times\text{SE}(b_1)$                                              |

When sample sizes are *small*, use the $t$ distribution, *not* 1.96, and check assumptions.

---

# 3 Interactive Exercise (R)

Simulate 5 000 polls of $n=500$ voters where the true support for a candidate is $p=0.54$.
Plot the 95 % CI for each poll and examine how often it captures the true 0.54.

```{r}
set.seed(2025)
n_sims <- 5000
n_poll <- 500
true_p <- 0.54

poll_p  <- rbinom(n_sims, n_poll, true_p) / n_poll
poll_se <- sqrt(poll_p * (1 - poll_p) / n_poll)
lo      <- poll_p - 1.96 * poll_se
hi      <- poll_p + 1.96 * poll_se
covered <- lo <= true_p & hi >= true_p
mean(covered)  # proportion of intervals that cover 0.54
```

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)

tibble(idx = 1:100, lo = lo[1:100], hi = hi[1:100], covered = covered[1:100]) %>%
  ggplot(aes(y = idx, yend = idx, x = lo, xend = hi, colour = covered)) +
  geom_segment(linewidth = 1.1) +
  geom_vline(xintercept = true_p, linetype = "dashed") +
  scale_colour_manual(values = c("red", "black")) +
  labs(title = "First 100 simulated 95 % CIs for poll proportion",
       x = "Proportion favouring Candidate A",
       y = NULL,
       colour = "Contains true p?") +
  theme_minimal()
```

The simulation should show ≈ 95 % coverage, visually reinforcing the CI definition.

---

# Key Takeaways

* **SE describes precision; SD describes raw variability.**
* **Confidence intervals = point estimate ± (critical value × SE).**
* **Larger $n$ or lower variability → narrower CI; higher confidence → wider CI.**
* CIs and two-sided hypothesis tests at the same α tell identical stories.
* Always check assumptions: randomness, independence, and—for small samples—approximate normality.

# Contributors {.unlisted .unnumbered}

The following team members contributed to this lesson:

`r .tgc_contributors_list(ids = c("joy", "kendavidn"))`

# References {.unlisted .unnumbered}

Some material in this lesson was adapted from the following sources:

-   Irizarry, Rafael A. 2019. *Introduction to Data Science: Statistics and Prediction Algorithms Through Case Studies*. <https://rafalab.dfci.harvard.edu/dsbook-part-2/>.
-   Cannell, Brad, and Melvin Livingston. n.d. *R for Epidemiology*. <https://www.r4epi.com/>.
-   GeeksforGeeks. 2025. "Introduction of Statistics and Its Types." <https://www.geeksforgeeks.org/introduction-of-statistics-and-its-types/>.
-   Starmer, Josh. *StatQuest with Josh Starmer* \[YouTube Channel\]. <https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw>.
-   The GRAPH Courses. *FoSSA: Fundamentals of Statistical Software & Analysis*. <https://thegraphcourses.org/courses/fossa/>.
-   University of Miami Libraries. *Introduction to Data Analysis and R*. <https://www.library.miami.edu/data-services/data-analysis.html>.

`r .tgc_license()`


