---
title: 'Estimation 2: Standard Error and Confidence intervals'
format:
  html:
    embed-resources: true
---

```{r, echo = F, message = F, warning = F}
# Load packages
if (!require(pacman)) install.packages("pacman")
pacman::p_load(rlang, tidyverse, knitr, here, reactable)

# Source functions
source(here("global/functions/lesson_functions.R"))

# Knitr options
knitr::opts_chunk$set(
  warning = F, message = F,
  class.source = "tgc-code-block", error = T
)

# Set ggplot theme
theme_set(theme_minimal())
```

# Introduction

How sure can we be that an election poll, a drug trial, or a customer‑satisfaction survey reflects the real world?

Today we’ll unlock the statistician’s answer: confidence intervals.

# Data

```{r}
diabetes_china_chen <- read_csv(here::here("data/diabetes_china_chen.csv"))
```

# Standard error

Sampling distribution gets narrower as sample size increases.

Increasing sample size – shape and central location stays the same, but variability decreases as sample size increases.

Normally we use standard deviation to describe the spread of data, BUT HERE IT IS NOT A DATA DISTRIBUTION BUT THIS IS THE VARIABILITY OF A STATISTIC, CALCULATED OVER EVERY POSSIBLE SAMPLE. SO HERE THE SD HAS A SPECIAL NAME: STANDARD ERROR.

The SE is the standard deviation of a sampling distribution.

## Standard error formula

$$\text{SE = SD of all sample means} = \frac{\text{population SD}}{\sqrt {\text{number in sample}}}$$

$$\text{SE} = \frac{\sigma}{\sqrt{n}}$$

$$\text{SE = SD of all sample means} \approx \frac{\text{sample SD}}{\sqrt {\text{number in sample}}}$$

$$\text{SE} \approx \frac{s}{\sqrt{n}}$$

Increasing sample size decreases the SE. Note: not linear because sqrt.

```{r}
# Worked example


```

## Table of key differences:

Standard Deviation is used for **description of data**:

-   quantifies the spread of individuals

-   describes variability in the data

Standard Error is used for **inference**:

-   quantifies the spread of the sample statistic

-   estimates the precision of sample statistic

-   decreases with increasing sample size.

| Measure | Primary Use | What It Quantifies | Extra Notes |
|----|----|----|----|
| **Standard Deviation (SD)** | Description of data (descriptive statistics) | Variability / spread of individual observations around the mean | Same units as the original data; always non-negative |
| **Standard Error (SE)** | Inference about a population (inferential statistics) | Precision / spread of a sample statistic across repeated samples | $$\text{SE} = \dfrac{\text{SD}}{\sqrt{n}}$$; decreases as sample size $n$ increases |

# Confidence Intervals

Sampling distribution and standard error are used in the calculation of confidence intervals.

::: callout-tip
Recap of estimation:

We rarely have data for every single individual in a population. Instead, we draw a **sample** and calculate **statistics**—like the mean or proportion—as **point estimates** of the unknown population parameters.

But every sample is a little different, so our estimate will wiggle around the true value.

Imagine repeating the sampling process thousands of times. The collection of those point estimates forms a **sampling distribution**.\
Its spread is captured by the **standard error (SE)**—literally, the standard deviation of that sampling distribution.

*Visual: Histogram of repeated sample means; overlay the SE as a horizontal bracket.*

**Key idea:** Smaller SE ⇒ tighter distribution ⇒ more precise estimates.
:::

So how can we make inferences about the value population parameter which encapsulates our uncertainty? ANSWER: CONFIDENCE INTERVALS!

A **confidence interval** stretches from the point estimate outwards by a multiple of the SE.\
For a 95 % CI under normality:

$$CI = 3.2 \pm 1.96 \times 0.25 = 3.2 \pm 0.49$$

Result: $$[2.71h, 3.69h]$$

That 1.96 is the critical value that captures the central 95 % of the standard normal distribution.”

*Visual: Normal curve shaded in middle 95 %, 1.96 marks.*

Careful! A 95 % CI does **not** mean there’s a 95 % chance the true parameter is inside *this* particular interval.\
It means that if we repeated the study over and over, 95 % of those intervals would contain the true parameter.”

*Visual: Multiple intervals across a horizontal axis; most overlap the dashed true value line.*

Notice the link to p‑values: if a 95 % CI for the difference between two treatments includes 0, the corresponding two‑sided p‑value will be greater than 0.05—so we call the difference ‘not statistically significant.’

## What Shrinks or Widens a CI?

| Factor                              | Effect on CI Width               |
|-------------------------------------|----------------------------------|
| **Sample size (n)** ↑               | SE ↓ ⇒ CI **narrows**            |
| **Confidence level** ↑ (e.g., 99 %) | Critical value ↑ ⇒ CI **widens** |
| **Data variability (σ)** ↑          | SE ↑ ⇒ CI **widens**             |

More data ➜ more confidence; tougher confidence level ➜ wider safety net.

## Worked Example

**Scenario:** We sampled 100 students; the mean study‑time is 3.2 h with an SE of 0.25 h.\
**Compute** a 95 % CI.

$$CI =  \pm 1.96 \times SE$$

$$CI = 3.2 \pm 1.96 \times 0.25 = 3.2 \pm 0.49$$

**Result:** $$[2.71h, 3.69h]$$

Interpretation: We’re 95 % confident that the average study‑time for *all* students sits between 2.7 and 3.7 hours.

*Visual: Horizontal line with shaded interval.*

## Key Takeaways

-   Point estimates are single best guesses.

-   Confidence intervals add a **measure of uncertainty**.

-   Width depends on sample size, variability, and chosen confidence level.

-   CIs and p‑values tell consistent stories about statistical significance.
